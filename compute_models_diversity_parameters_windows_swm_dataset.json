{
    "input": {
        "experiment": {
            "id": "e016-SWM",
            "description": "Evaluation of DiODeFusion and DiCODeFusion the SWM Dataset (Sclerotinia and White Mold) with Voting and WBF fusion."
        },
        "predictions_folder_path": "model-diversity-dataset/",
        "dataset_name": "swm-dataset",
        "dataset_description": "White Mold Dataset",
        "object_detection_models": {
            "ssd": ["ssd", true],
            "faster_rcnn": ["faster_rcnn", true],
            "yolov8": ["yolov8", true],
            "yolov9": ["yolov9", true],
            "yolov10": ["yolov10", true],
            "detr": ["detr", true],
            "trans_unet": ["trans_unet", false]
        },       
        "diversity_measures_computing": {
            "iou_threshold": 0.3
        },
        "input_dataset": {
            "input_image_size": 300,
            "annotation_format": "ssd_pascal_voc",
            "convert_pascal_voc_to_coco_format": false,
            "input_dataset_path": "white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset"
        },
        "object_detection_models_selection_methods": {
            "all_diversity_measures_with_no_tiebreak": {
                "apply": true, 
                "short_name": "m01-all-div", 
                "description": "Selection of object detection models based on all diversity measures together and no tiebreak criteria",
                "top_t" : 2
            },
            "single_diversity_measure_with_tiebreak": {
                "apply": true, 
                "short_name": "m02-single-div", 
                "description": "Selection of detection models based on single diversity measure and tiebreak criteria",
                "top_t" : 2
            },
            "single_diversity_measure_with_tiebreak_and_effectivenes_filter": {
                "apply": true, 
                "short_name": "m03-single-div-filter", 
                "description": "Selection of object detection models based on single diversity measure, effectiveness-driven detector filter and tiebreak criteria",
                "top_t" : 2,
                "f1_score_threshold_for_valid_dataset": 0.70
            },
            "hierarchical_clustering_based_on_diversity_measure": {
                "apply": true, 
                "short_name": "m04-clustering", 
                "description": "Selection of object detection models based on hierarchical clustering and diversity measures, effectiveness-driven detector and tiebreak criteria",
                "minimum_models_in_cluster": 2
            },
            "hierarchical_clustering_based_on_diversity_measure_filtered": {
                "apply": true, 
                "short_name": "m05-clustering-filtered", 
                "description": "Selection of object detection models based on hierarchical clustering and diversity measures, effectiveness-driven detector filter and tiebreak criteria",
                "minimum_models_in_cluster": 2,
                "f1_score_threshold_for_valid_dataset": 0.70
            }
        },
        "distance_function": {
            "cor": ["cor", "Correlation Coefficient", false, "correlation_coefficient"],
            "dfm": ["dfm", "Double Fault Measure", false, "double_fault_measure"],
            "dm": ["dm", "Disagreement Measure", false, "disagreement_measure"],
            "ia": ["ia", "Interrater Agreement", false, "interrater_agreement"],
            "qstat": ["qstat", "Q-Statistic", true, "q_statistic"]
        },
        "bounding_boxes_fusion_methods": {
            "voting_scheme": {
                "apply": true, 
                "short_name": "voting", 
                "description": "Fusion methods based on prediction voting scheme: affirmative, consensus, and unanimous.",
                "iou_threshold_for_grouping": 0.2,
                "iou_threshold_for_inference": 0.3,
                "non_maximum_suppression": 0.9
            },
            "weighted_boxes_fusion": {
                "apply": true, 
                "short_name": "wbf", 
                "description": "Weighted boxes fusion (WBF)",
                "iou_threshold_for_matched_boxes": 0.5,
                "iou_threshold_for_inference": 0.3,
                "minimum_fused_bounding_boxes": 0
            }
        }
    },

    "model_ssd": {
        "input": {
            "predictions_json": {
                "train": "ssd-train-exp-012-pred-running-0003-predictions",
                "valid": "ssd-valid-exp-012-pred-running-0002-predictions.json",
                "test": "ssd-test-exp-012-pred-running-0001-predictions.json"
            }
        }, 
        "neural_network_model": {
            "iou_threshold": 0.3
        }
    },

    "model_faster_rcnn": {
        "input": {
            "predictions_json": {
                "train": "faster_rcnn-train-exp-012-pred-running-0003-predictions.json",
                "valid": "faster_rcnn-valid-exp-012-pred-running-0002-predictions.json",
                "test": "faster_rcnn-test-exp-012-pred-running-0001-predictions.json"
            },
            "input_dataset": {
                "input_image_size": 300,
                "annotation_format": "faster_rcnn",
                "input_dataset_path": "white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset",
                "input_dataset_type": "train"
            },
            "inference": {
                "weights_folder": "/home/lovelace/proj/proj939/rubenscp/research/white-mold-inference-weights/exp-006-training-300x300-merging-classes-balanced-image-all-classes",
                "weights_filename": "faster-rcnn-resnet-50-fpn-running-0631-300x300.pth"    

            }
        }, 
        "neural_network_model": {
            "iou_threshold": 0.3
        }
    },

    "model_yolov8": {
        "input": {
            "predictions_json": {
                "train": "yolov8-train-exp-012-pred-running-0004-predictions.json",
                "valid": "yolov8-valid-exp-012-pred-running-0002-predictions.json",
                "test": "yolov8-test-exp-012-pred-running-0001-predictions.json"
            },
            "input_dataset": {
                "input_image_size": 300,
                "annotation_format": "yolov8",
                "input_dataset_path": "white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset",
                "input_dataset_type": "train"
            },
            "inference": {
                "weights_folder": "/home/lovelace/proj/proj939/rubenscp/research/white-mold-inference-weights/exp-006-training-300x300-merging-classes-balanced-image-all-classes",
                "weights_filename": "yolov8s.pt-running-0635-300x300.pt"
            }
        }, 
        "neural_network_model": {
            "model_name": "yolov8s.pt",
            "number_of_classes": 5,        
            "threshold": 0.3,
            "iou_threshold": 0.3,
            "non_maximum_suppression": 0.5 
        },
        "processing": {
            "yolo_yaml_filename_test": "white_mold_yolov8_test.yaml"
        }
    },

    "model_yolov9": {
        "input": {
            "predictions_json": {
                "train": "yolov9-train-exp-012-pred-running-0004-predictions.json",
                "valid": "yolov9-valid-exp-012-pred-running-0002-predictions.json",
                "test": "yolov9-test-exp-012-pred-running-0001-predictions.json"
            },
            "input_dataset": {
                "input_image_size": 300,
                "annotation_format": "yolov8",
                "input_dataset_path": "white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset",
                "input_dataset_type": "train"
            },
            "inference": {
                "weights_folder": "/home/lovelace/proj/proj939/rubenscp/research/white-mold-inference-weights/exp-006-training-300x300-merging-classes-balanced-image-all-classes",
                "weights_filename": "yolov9c.pt-running-0640-300x300.pt"
            }
        }, 
        "neural_network_model": {
            "model_name": "yolov9c.pt",
            "number_of_classes": 5,        
            "threshold": 0.3,
            "iou_threshold": 0.5,
            "non_maximum_suppression": 0.5
        },
        "processing": {
            "yolo_yaml_filename_test": "white_mold_yolov9_test.yaml"
        }
    },

    "model_yolov10": {
        "input": {
            "predictions_json": {
                "train": "yolov10-train-exp-012-pred-running-0004-predictions.json",
                "valid": "yolov10-valid-exp-012-pred-running-0002-predictions.json",
                "test": "yolov10-test-exp-012-pred-running-0001-predictions.json"
            },
            "input_dataset": {
                "input_image_size": 300,
                "annotation_format": "yolov8",
                "input_dataset_path": "white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset",
                "input_dataset_type": "train"
            },
            "inference": {
                "weights_folder": "/home/lovelace/proj/proj939/rubenscp/research/white-mold-inference-weights/exp-008-training-300x300-merging-classes-balanced-image-all-classes",
                "weights_filename": "yolov10x.pt-running-0053-300x300.pt"
            }
        }, 
        "neural_network_model": {
            "model_name": "yolov10x.pt",
            "number_of_classes": 5,        
            "threshold": 0.3,
            "iou_threshold": 0.3,
            "non_maximum_suppression": 0.5
        },
        "processing": {
            "yolo_yaml_filename_test": "white_mold_yolov10_test.yaml"
       }
    },

    "model_detr": {
        "input": {
            "predictions_json": {
                "train": "detr-train-exp-012-pred-running-0005-predictions.json",
                "valid": "detr-valid-exp-012-pred-running-0002-predictions.json",
                "test": "detr-test-exp-012-pred-running-0001-predictions.json"
            },
            "input_dataset": {
                "input_image_size": 300,
                "annotation_format": "coco_detection_json",
                "input_dataset_path": "white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset",
                "input_dataset_type": "train"
            },
            "inference": {
                "weights_folder": "/home/lovelace/proj/proj939/rubenscp/research/white-mold-inference-weights/exp-007-training-300x300-merging-classes-balanced-image-all-classes",
                "weights_filename": "detr-resnet-50-running-0316-300x300.pth"
            }
        }, 
        "neural_network_model": {
            "pretrained_model_path": "/home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/wm-pretrained-model/detr-resnet-50",
            "model_name": "detr-resnet-50",
            "model_cache_dir": "/home/lovelace/proj/proj939/rubenscp/.cache/huggingface/hub",
            "comment_number_of_classes": "consider number of classes plus the background class",
            "number_of_classes": 6,        
            "threshold": 0.5,
            "iou_threshold": 0.3,
            "non_maximum_suppression": 0.9,
            "weight_decay": 0.0001,
            "learning_rate_initial": 0.0001,
            "learning_rate_backbone": 0.00001   
        }
    },

    "model_transunet": {
        "input": {
            "predictions_json": {
                "train": "xxxxxxx.json",
                "valid": "xxxxxxxxxxxxxxxx.json",
                "test": "xxxxxxxxxxxxxxxxxxxxx.json"
            },
            "input_dataset": {
                "input_image_size": 300,
                "annotation_format": "coco_detection_json",
                "input_dataset_path": "white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset",
                "input_dataset_type": "train"
            },
            "inference": {
                "weights_folder": "/home/lovelace/proj/proj939/rubenscp/research/white-mold-inference-weights/exp-007-training-300x300-merging-classes-balanced-image-all-classes",
                "weights_filename": "detr-resnet-50-running-0316-300x300.pth"
            }
        }, 
        "neural_network_model": {
            "model_name": "transunet",
            "threshold": 0,
            "iou_threshold": 0.3
        }
    },

    "neural_network_model": {
        "model_name": "model-diversity",
        "resize_of_input_image": 300,
        "threshold": -1,
        "NOT_USED_iou_threshold_for_grouping": 0.1,
        "NOT_USED_iou_threshold_for_inference": 0.1,
        "non_maximum_suppression": 0.1,
        "number_workers": 7,
        "comment_number_of_classes": "consider number of classes plus the background class",
        "number_of_classes": 5,       
        "classes": [
            "__background__", 
            "Apothecium", 
            "Imature Sclerotium", 
            "Mature Sclerotium", 
            "White Mold", 
            "Imature Sclerotium and White Mold",            
            "class 6", "class 7", "class 8", "class 9", "class 10",
            "class 11", "class 12", "class 13", "class 14", "class 15", "class 16", "class 17", "class 18", "class 19", "class 20",
            "class 21", "class 22", "class 23", "class 24", "class 25", "class 26", "class 27", "class 28", "class 29", "class 30",
            "class 31", "class 32", "class 33", "class 34", "class 35", "class 36", "class 37", "class 38", "class 39", "class 40",
            "class 41", "class 42", "class 43", "class 44", "class 45", "class 46", "class 47", "class 48", "class 49", "class 50",
            "class 51", "class 52", "class 53", "class 54", "class 55", "class 56", "class 57", "class 58", "class 59", "class 60",
            "class 61", "class 62", "class 63", "class 64", "class 65", "class 66", "class 67", "class 68", "class 69", "class 70",
            "class 71", "class 72", "class 73", "class 74", "class 75", "class 76", "class 77", "class 78", "class 79", "class 80",
            "class 81", "class 82", "class 83", "class 84", "class 85", "class 86", "class 87", "class 88", "class 89", "class 90"         
        ],
        "classes_short_name": [
            "__background__",
            "Apoth", 
            "Imat Scler", 
            "Mat Scler", 
            "White Mold", 
            "White Mold",
            "class 6", "class 7", "class 8", "class 9", "class 10",
            "class 11", "class 12", "class 13", "class 14", "class 15", "class 16", "class 17", "class 18", "class 19", "class 20",
            "class 21", "class 22", "class 23", "class 24", "class 25", "class 26", "class 27", "class 28", "class 29", "class 30",
            "class 31", "class 32", "class 33", "class 34", "class 35", "class 36", "class 37", "class 38", "class 39", "class 40",
            "class 41", "class 42", "class 43", "class 44", "class 45", "class 46", "class 47", "class 48", "class 49", "class 50",
            "class 51", "class 52", "class 53", "class 54", "class 55", "class 56", "class 57", "class 58", "class 59", "class 60",
            "class 61", "class 62", "class 63", "class 64", "class 65", "class 66", "class 67", "class 68", "class 69", "class 70",
            "class 71", "class 72", "class 73", "class 74", "class 75", "class 76", "class 77", "class 78", "class 79", "class 80",
            "class 81", "class 82", "class 83", "class 84", "class 85", "class 86", "class 87", "class 88", "class 89", "class 90"         
        ]
    },
    "processing": {
        "research_root_folder": "e:\\Doctorate",
        "project_name_folder": "white-mold-applications/wm-model-diversity",
        "running_control_filename": "running_control.json",
        "running_id": "defined during training/test ",
        "running_id_text": "defined during training/inference ",
        "NOT_image_dataset_folder": "defined during training/test ",
        "NOT_image_dataset_folder_test": "defined during training/test ",
        "NOT_show_statistics_of_input_dataset": true
    },
    "results": {
        "main_folder": "wm-results",
        "model_folder": "defined during training/test",
        "experiment_folder": "experiment",
        "action_folder": "test",
        "running_folder": "defined during training/test",
        "processing_parameters_folder": "processing-parameters",
        "pretrained_model_folder": "pretrained-model",
        "weights_folder": "weights",
        "metrics_folder": "metrics",
        "inferenced_image_folder": "tested-image",
        "affirmative_strategy_folder": "ensemble-affirmative",
        "consensus_strategy_folder": "ensemble-consensus",
        "unanimous_strategy_folder": "ensemble-unanimous",
        "log_folder": "log",
        "log_filename": "compute_models_diversity",
        "results_folder": "results",
        "predictions_folder": "predictions",
        "matrices_folder": "matrices",
        "performance_metrics_folder": "performance-metrics",
        "m01_all_div_folder": "m01-all-div",
        "m02_single_div_folder": "m02-single-div",
        "m03_single_div_filter_folder": "m03-single-div-filter",
        "m04_clustering_folder": "m04-clustering",
        "m05_clustering_filter_folder": "m05-clustering-filter",
        "bboxes_fusion_folder": "bboxes-fusion"
    }
}
